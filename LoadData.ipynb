{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pydicom as dicom\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nibabel as nib\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from tensorflow.data.experimental import sample_from_datasets\n",
    "from tensorflow.image import central_crop\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "from tensorflow.keras import Model\n",
    "from skimage.util import crop\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import initializers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshaping(array):\n",
    "    array = tf.expand_dims(array, axis = -1)\n",
    "    return(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folders():\n",
    "    \"\"\"\n",
    "    Returns a list of all the folders in the HGG and LGG directories.\n",
    "    \"\"\"\n",
    "    HGG_Folders= os.listdir(r'C:\\Users\\Joe Krinke\\Desktop\\BraTS 2019 Data\\MICCAI_BraTS_2019_Data_Training\\HGG')\n",
    "    LGG_Folders = os.listdir(r'C:\\Users\\Joe Krinke\\Desktop\\BraTS 2019 Data\\MICCAI_BraTS_2019_Data_Training\\LGG')\n",
    "    return(HGG_Folders, LGG_Folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nii_data(filename):\n",
    "    \"\"\"\n",
    "    Load in an nii file and return an array containing the pixel data. \n",
    "    inputs:\n",
    "        filename (string): The name of the nii file you want to load.\n",
    "    outputs:\n",
    "        array (numpy array): A numpy array of the given image.\n",
    "    \"\"\"\n",
    "    image = nib.load(filename)\n",
    "    array = image.get_fdata()\n",
    "    array = array.astype(np.uint8)\n",
    "    return(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img, start, end):\n",
    "    img = img[start:end, start:end, :]\n",
    "    return(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scale(img):\n",
    "    \"\"\"\n",
    "    Scale the features of the image from 0 to 1\n",
    "    \"\"\"\n",
    "    img *= 255.0/img.max()  \n",
    "    return (img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxel_clip(img):\n",
    "    \"\"\"\n",
    "    Clips the image to the 2nd and 98th percentile values.\n",
    "    inputs:\n",
    "        img (a numpy array): The image you want to clip\n",
    "    outputs:\n",
    "        img (a numpy array): The image with its values clipped\n",
    "    \"\"\"\n",
    "    upper = np.percentile(img, 98)\n",
    "    lower = np.percentile(img, 2)\n",
    "    img[img > upper] = upper\n",
    "    img[img < lower] = lower\n",
    "    return(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bool(array):\n",
    "    array = np.where(array>0, 1, 0)\n",
    "    return(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGG_data_generator():\n",
    "    \"\"\"\n",
    "    Create dataset of LGG data.\n",
    "    inputs:\n",
    "        path (string): The path where the folders containing the images are located.\n",
    "    outputs:\n",
    "        Yields image, mask tuples. Each mask appears with its corresponding image. Masks appear multiple times (once for each image type: t1,t2, etc.).\n",
    "        \n",
    "    \"\"\"\n",
    "    path = r'C:/Users/Joe Krinke/Desktop/BraTS 2019 Data/MICCAI_BraTS_2019_Data_Training/'\n",
    "    image_types = ['flair', 't1', 't2', 't1ce']\n",
    "    HGG_Folders, LGG_Folders = get_folders()\n",
    "                         \n",
    "    for i in LGG_Folders:\n",
    "        mask = load_nii_data(path + 'LGG/' + i + '/' + i + '_' + 'seg' + '.nii.gz')\n",
    "        # Crop Mask\n",
    "        mask = crop(mask, 0,224)\n",
    "        for types in image_types:\n",
    "            # crop image, clip it\n",
    "            data = load_nii_data(path + 'LGG/' + i + '/' + i + '_' + types + '.nii.gz')\n",
    "            data = crop(data, 0, 224)\n",
    "            data = voxel_clip(data)\n",
    "            img_counter = 0\n",
    "            for j in range(data.shape[2]):\n",
    "                img_counter += 1 \n",
    "                yield(reshaping(data[:,:,j]), reshaping(convert_bool(mask[:,:,j])))\n",
    "\n",
    "\n",
    "def HGG_data_generator():\n",
    "    \"\"\" \n",
    "    Create dataset of HGG data.\n",
    "    inputs:\n",
    "        path (string): The path where the folders containing the images are located.\n",
    "    outputs:\n",
    "        Yields image, mask tuples. Each mask appears with its corresponding image. Masks appear multiple times (once for each image type: t1,t2, etc.).\n",
    "        \n",
    "    \"\"\"\n",
    "    path = r'C:/Users/Joe Krinke/Desktop/BraTS 2019 Data/MICCAI_BraTS_2019_Data_Training/'\n",
    "    image_types = ['flair', 't1', 't2', 't1ce']\n",
    "    HGG_Folders, LGG_Folders = get_folders()\n",
    "    for i in HGG_Folders:\n",
    "        mask = load_nii_data(path + 'HGG/' + i + '/' + i + '_' + 'seg' + '.nii.gz')\n",
    "        # Crop Mask\n",
    "        mask = crop(mask, 0, 224)\n",
    "        for types in image_types:\n",
    "            data = load_nii_data(path + 'HGG/'+ i + '/'+ i + '_' + types + '.nii.gz')\n",
    "            # crop image, clip it\n",
    "            data = crop(data, 0, 224)\n",
    "            data = voxel_clip(data)\n",
    "            img_counter = 0\n",
    "            for j in range(data.shape[2]):\n",
    "                img_counter += 1 \n",
    "                yield(reshaping(data[:,:,j]), reshaping(convert_bool(mask[:,:,j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create both datasets\n",
    "HGG_dataset = tf.data.Dataset.from_generator(HGG_data_generator, output_types = (tf.uint8, tf.uint8), output_shapes = (tf.TensorShape([224,224,1]), tf.TensorShape([224,224,1])))\n",
    "LGG_dataset = tf.data.Dataset.from_generator(LGG_data_generator, output_types = (tf.uint8,tf.uint8), output_shapes = (tf.TensorShape([224,224,1]), tf.TensorShape([224,224,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master dataset with examples from both datasets\n",
    "full_dataset = tf.data.experimental.sample_from_datasets([HGG_dataset, LGG_dataset], seed =123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_size = (224,224,1)):\n",
    "    ''' \n",
    "    U-Net model.\n",
    "    Inputs:\n",
    "        input_size(tuple):  Model input size\n",
    "    '''\n",
    "\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same',\n",
    "                kernel_initializer=initializers.random_normal(stddev=0.01))(conv5),conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same',\n",
    "                kernel_initializer=initializers.random_normal(stddev=0.01))(conv6),conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2),padding='same',\n",
    "                kernel_initializer=initializers.random_normal(stddev=0.01))(conv7),conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same',)(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same',\n",
    "                kernel_initializer=initializers.random_normal(stddev=0.01))(conv8),conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "                   kernel_initializer=initializers.random_normal(stddev=0.01))(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='relu',\n",
    "                    kernel_initializer=initializers.random_normal(stddev=0.01))(conv9)\n",
    "    conv10 = Activation('sigmoid')(conv10)\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    lr = 1e-5\n",
    "    model.compile(optimizer=Adam(lr=lr), loss='BinaryCrossentropy', metrics=['BinaryCrossentropy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_33\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 224, 224, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 224, 224, 32) 320         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 224, 224, 32) 9248        conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling2D) (None, 112, 112, 32) 0           conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 112, 112, 64) 18496       max_pooling2d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 112, 112, 64) 36928       conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling2D) (None, 56, 56, 64)   0           conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 56, 56, 128)  73856       max_pooling2d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 56, 56, 128)  147584      conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling2D) (None, 28, 28, 128)  0           conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 28, 28, 256)  295168      max_pooling2d_66[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 28, 28, 256)  590080      conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling2D) (None, 14, 14, 256)  0           conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 14, 14, 512)  1180160     max_pooling2d_67[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 14, 14, 512)  2359808     conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_64 (Conv2DTran (None, 28, 28, 256)  524544      conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 28, 28, 512)  0           conv2d_transpose_64[0][0]        \n",
      "                                                                 conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 28, 28, 256)  1179904     concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 28, 28, 256)  590080      conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_65 (Conv2DTran (None, 56, 56, 128)  131200      conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 56, 56, 256)  0           conv2d_transpose_65[0][0]        \n",
      "                                                                 conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 56, 56, 128)  295040      concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 56, 56, 128)  147584      conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_66 (Conv2DTran (None, 112, 112, 64) 32832       conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 112, 112, 128 0           conv2d_transpose_66[0][0]        \n",
      "                                                                 conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 112, 112, 64) 73792       concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 112, 112, 64) 36928       conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_67 (Conv2DTran (None, 224, 224, 32) 8224        conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 224, 224, 64) 0           conv2d_transpose_67[0][0]        \n",
      "                                                                 conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 224, 224, 32) 18464       concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 224, 224, 32) 9248        conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 224, 224, 1)  33          conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 224, 224, 1)  0           conv2d_322[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,759,521\n",
      "Trainable params: 7,759,521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data train and val size\n",
    "data_size = 0\n",
    "for element in full_dataset:\n",
    "    data_size += 1\n",
    "train_size = int(0.80* data_size)\n",
    "val_size = int(0.20 * data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation datasets\n",
    "train_dataset = full_dataset.take(train_size)\n",
    "val_dataset = full_dataset.skip(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train = train_dataset.batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 224, 224, 1), (None, 224, 224, 1)), types: (tf.uint8, tf.uint8)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "    263/Unknown - 52s 197ms/step - loss: 0.6931 - binary_crossentropy: 0.6931"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-b431d792c2e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_model.fit(batch_train,epochs=20, verbose=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
